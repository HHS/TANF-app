"""
Script to extract field names from schema definition files in the schema_defs directory.

This script will output a json file where keys are schema file names and values are lists of field names.
"""

import os
import sys
import re
import json
import logging
from collections import defaultdict

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def extract_field_names(schema_file_path):
    """Extract field names from a schema file using regex pattern matching."""
    try:
        with open(schema_file_path, 'r') as file:
            content = file.read()

        # Pattern to match Field or TransformField declarations and extract the name parameter
        field_pattern = r'(?:Field|TransformField)\s*\([^\)]*?\s*name\s*=\s*[\'\"](\w+)[\'\"]'
        field_names = re.findall(field_pattern, content)

        # Remove duplicates while preserving order
        seen = set()
        unique_field_names = []
        for name in field_names:
            if name not in seen and name != "BLANK":
                seen.add(name)
                unique_field_names.append(name)

        return unique_field_names
    except Exception as e:
        logger.error(f"Error processing {schema_file_path}: {str(e)}")
        return []


def find_schema_files(base_dir):
    """Find all schema definition files in the given directory and its subdirectories."""
    schema_files = []

    for root, dirs, files in os.walk(base_dir):
        for file in files:
            if file.endswith('.py') and file != '__init__.py' and file != 'utils.py':
                schema_files.append(os.path.join(root, file))

    return schema_files


def main():
    """Generate schema_fields.json."""
    logger.info("Starting schema field extraction")
    # Path to the schema_defs directory
    schema_defs_dir = os.path.join(
        os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))),
        'tdpservice', 'parsers', 'schema_defs'
    )

    if not os.path.exists(schema_defs_dir):
        logger.error(f"Schema directory not found at {schema_defs_dir}")
        sys.exit(1)

    # Find all schema files
    schema_files = find_schema_files(schema_defs_dir)

    # Extract field names from each schema file
    results = defaultdict(list)
    for schema_file in schema_files:
        # Get relative path for cleaner output
        rel_path = os.path.relpath(schema_file, schema_defs_dir)
        field_names = extract_field_names(schema_file)
        if field_names:
            # Group by schema directory (e.g., tanf, fra, ssp, tribal_tanf)
            schema_type = os.path.dirname(rel_path)
            if not schema_type:  # skip header and trailer
                continue

            schema_name = os.path.basename(rel_path).replace('.py', '')
            if schema_type not in results:
                results[schema_type] = {}
            results[schema_type][schema_name] = field_names

    # Create a dictionary with a comment and the results
    output_with_comment = {
        "_comment": "THIS FILE IS GENERATED BY extract_schema_fields.py. DO NOT EDIT MANUALLY.",
        "generated_at": f"{__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "schemas": results
    }

    # Print results in a readable format
    output = json.dumps(output_with_comment, indent=2, sort_keys=True)

    # Save results to a file
    output_file = 'schema_fields.json'
    with open(output_file, 'w') as f:
        f.write(output)
    logger.info(f"Results saved to {output_file}")


if __name__ == "__main__":
    main()
